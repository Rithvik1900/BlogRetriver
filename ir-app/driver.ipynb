{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc47b243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] A\n",
      "[nltk_data]     connection attempt failed because the connected party\n",
      "[nltk_data]     did not properly respond after a period of time, or\n",
      "[nltk_data]     established connection failed because connected host\n",
      "[nltk_data]     has failed to respond>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "import os\n",
    "from traitlets import default\n",
    "import streamlit as st\n",
    "#from streamlit_option_menu import option_menu\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from utils import cosine_similarity\n",
    "#from page1 import page1_1,page1_2,page1_3,page1_4,page1_5\n",
    "from st_aggrid import GridOptionsBuilder, AgGrid, GridUpdateMode, DataReturnMode\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "import regex as re\n",
    "from rank_bm25 import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ebab898",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLs = [\"https://medium.com/towards-data-science/statistics-for-people-in-a-hurry-a9613c0ed0b\",\n",
    "       \"https://medium.com/towards-data-science/a-quick-guide-to-relational-algebra-operators-in-dbms-1ff2ddecaad7\",\n",
    "        \"https://medium.com/grokking-the-tech-interview/the-top-data-structures-you-should-know-for-your-next-coding-interview-36af0831f5e3\",\n",
    "        \"https://medium.com/cometheartbeat/the-5-computer-vision-techniques-that-will-change-how-you-see-the-world-1ee19334354b\",\n",
    "]\n",
    "\n",
    "filename = \"\"\"C:/Users/ai/OneDrive/Desktop/Temp/Ritvick/ir-app/data/IR Links.txt\"\"\"\n",
    "URLs = []\n",
    "with open(filename) as file:\n",
    "    for line in file:\n",
    "        URLs.append(line.rstrip())\n",
    "URLs = URLs[1:]\n",
    "soups = []\n",
    "for url in URLs:\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    soups.append(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f7761a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "titles = []\n",
    "\n",
    "for soup in soups:\n",
    "    sections = soup.find_all('section')\n",
    "    story_paragraphs = []\n",
    "    section_titles = []\n",
    "    for section in sections:\n",
    "        paragraphs = section.find_all('p')\n",
    "        for paragraph in paragraphs:\n",
    "            story_paragraphs.append(paragraph.text)\n",
    "\n",
    "        subs = section.find_all('h1')\n",
    "        for sub in subs:\n",
    "            section_titles.append(sub.text)\n",
    "    try:\n",
    "        titles.append(section_titles[0])\n",
    "    except:\n",
    "        titles.append(\"No Title\")\n",
    "        documents.append(\"No Content\")\n",
    "        continue\n",
    "    \n",
    "    document = \"\"\n",
    "    for para in story_paragraphs:\n",
    "        document = document+ para + \"\\n\"\n",
    "    documents.append(document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52161bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349, 349)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles),len(URLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a3f011af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 if doc==\"\" else 0 for doc in documents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "16a66808",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df[\"url\"] = URLs\n",
    "df[\"title\"] = titles\n",
    "df[\"content\"] = documents\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee81f3",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae1bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words={'english'})\n",
    "indices = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7921671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(query,keys):\n",
    "    p1 = query.dot(keys)\n",
    "    p2 = norm(keys,axis=0)*norm(query)\n",
    "    return p1/p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffdd5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(text):\n",
    "    index = vectorizer.transform([text]).toarray()[0]\n",
    "    index = np.expand_dims(index,axis=-1)\n",
    "    sim_scores = cosine_similarity(indices,index)\n",
    "    print(sim_scores)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9927e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05783263]\n",
      " [0.03906388]\n",
      " [0.12344652]\n",
      " [0.019242  ]]\n"
     ]
    }
   ],
   "source": [
    "recommend(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9c3c1",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bacea693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_specials(documents):\n",
    "    cleaned = list()\n",
    "    for text in documents:\n",
    "        word = re.sub(\"[0-9a-zA-Z]\",\" \",text)\n",
    "        cleaned.append(word)\n",
    "    return cleaned\n",
    "\n",
    "def remove_stopwords(documents):\n",
    "    cleaned = list()\n",
    "    for text in documents:\n",
    "        text_tokens = word_tokenize(text)\n",
    "        tokens_without_sw = [word for word in text_tokens if not word in STOPWORDS]\n",
    "        str_t = \" \".join(tokens_without_sw)\n",
    "        cleaned.append(str_t)\n",
    "    return cleaned\n",
    "\n",
    "def preprocess(documents):\n",
    "    cleaned = remove_specials(documents)\n",
    "    cleaned = remove_stopwords(documents)\n",
    "    return cleaned\n",
    "\n",
    "def process_documents():\n",
    "    \n",
    "    documents_cleaned = preprocess(documents)\n",
    "    bm25_index = prepare_indices(documents_cleaned)\n",
    "    return bm25_index\n",
    "\n",
    "def prepare_indices(documents):\n",
    "    \n",
    "    tokenized_corpus = [doc.split(\" \") for doc in documents]\n",
    "    bm25_index = BM25Okapi(tokenized_corpus)\n",
    "    return bm25_index\n",
    "\n",
    "def recommend_bm(text,top_k):\n",
    "    text = preprocess([text])[0]\n",
    "    tokenized_query = text.split(\" \")\n",
    "    scores = bm25_index.get_scores(tokenized_query)\n",
    "\n",
    "    recs = np.argsort(scores)[::-1][:top_k]\n",
    "    return recs\n",
    "\n",
    "bm25_index = process_documents()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44f19db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend_bm(\"data\",3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5847658a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dataenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c8a4bf918f543c4a38891cc532f906d65738c6ea827c56397be037d4432ed09"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
